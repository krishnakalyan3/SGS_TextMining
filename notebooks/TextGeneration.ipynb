{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CORPUS_PATH = os.path.join('data/sample/002')\n",
    "#CORPUS_PATH = os.path.join('data/001')\n",
    "filenames1 = sorted([os.path.join(CORPUS_PATH, fn) for fn in os.listdir(CORPUS_PATH)])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = ' '.join([open(i).read().lower() for i in filenames1])\n",
    "chars = sorted(set(list(' '.join(text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "print(len(char_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 1633\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(200))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/fastai/lib/python3.6/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1306 samples, validate on 327 samples\n",
      "Epoch 1/10\n",
      "1306/1306 [==============================] - 3s 2ms/step - loss: 3.4437 - val_loss: 3.1158\n",
      "Epoch 2/10\n",
      "1306/1306 [==============================] - 1s 1ms/step - loss: 2.9534 - val_loss: 3.0426\n",
      "Epoch 3/10\n",
      "1306/1306 [==============================] - 1s 1ms/step - loss: 2.7999 - val_loss: 2.8752\n",
      "Epoch 4/10\n",
      "1306/1306 [==============================] - 1s 1ms/step - loss: 2.6063 - val_loss: 2.7632\n",
      "Epoch 5/10\n",
      "1306/1306 [==============================] - 1s 1ms/step - loss: 2.3996 - val_loss: 2.7065\n",
      "Epoch 6/10\n",
      "1306/1306 [==============================] - 1s 1ms/step - loss: 2.2582 - val_loss: 2.6796\n",
      "Epoch 7/10\n",
      "1306/1306 [==============================] - 1s 1ms/step - loss: 2.1152 - val_loss: 2.6629\n",
      "Epoch 8/10\n",
      "1306/1306 [==============================] - 1s 1ms/step - loss: 1.9996 - val_loss: 2.6401\n",
      "Epoch 9/10\n",
      "1306/1306 [==============================] - 1s 1ms/step - loss: 1.8772 - val_loss: 2.6700\n",
      "Epoch 10/10\n",
      "1306/1306 [==============================] - 1s 1ms/step - loss: 1.7438 - val_loss: 2.7944\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=128, nb_epoch=10, validation_split=0.2)\n",
    "checkpointer = ModelCheckpoint(filepath=\"models\" + str(i) + \".hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('final_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"a species, and,\n",
      "instituting a “test and \"\n",
      "a species, and,\n",
      "instituting a “test and the and the and rometeres of cod ar or of the and the and the and the and the and the and the and the and the all and or or the and the and the and the and the and the and the and the alin the and the and the and ar of the are of the and the and the and the all tere of the and the and the and the all tes and the all and or or acs on the an the and the and the all ares of the and ard or the all ses\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"a species, and,\n",
      "instituting a “test and \"\n",
      "a species, and,\n",
      "instituting a “test and the on the ave the alua the aly ar ar or acor rsurd act reromutit an the allis ang an the nof the ar abell anf the armeation ar the on the and the the arme the an fourite the and teve alut ing for tha the ano durestent alis and cor cor ar od and te al dereace the alu tes and or coments tian in acteres productss od act and aly the the ang the and tha the galutat in ar the and or the oluactess an th\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"a species, and,\n",
      "instituting a “test and \"\n",
      "a species, and,\n",
      "instituting a “test and sulit engere\n",
      "palot the palt nd cotes, touen rosututie ano thay maablit blalig of coderosurof blokerereaw gathh weal loesacing prouttirs ard aro\n",
      "tarin medote milo perestpessind gale the ” okthath thale asnodm, anw ro0utit a;\n",
      "vo paluresrond the ang vealct the alf wesamulity dourthersessuctag oof roducfictevat coblulu in ang and rove profuctiarit autvengucing or oxtatsien ably alucetsmring ok nscolme\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"a species, and,\n",
      "instituting a “test and \"\n",
      "a species, and,\n",
      "instituting a “test and acintresuresth n thespelfvely tor the foducigereve ouring mocteres acrals tar was ing blu produvact,y fokubcontser, aklia,y.\n",
      "(o pactatint od on oldoare;.\n",
      "ofpcand is lon thin nod torom/bevorioq of tha y eraly th n jilnsutes ald ardesetara dualty no 'caresesuing ingactes nod ve sod faris nferesatitiot inn ar ths than, isfofucets aglilsicesint s nressieng ifhe redsptwectess, nd deranm dor.\n",
      "(h ca“3 fo"
     ]
    }
   ],
   "source": [
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "    print()\n",
    "    print('----- diversity:', diversity)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
